{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn\n",
    "!pip3 install transformers\n",
    "!pip3 install konlpy\n",
    "!pip3 install eunjeon\n",
    "!pip3 install torch\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "import torch\n",
    "import sklearn\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi = pd.read_excel('datas/감성대화말뭉치_훈련용.xlsx', names=['emotion','sentence'])\n",
    "mmc = malmungchi[['emotion','sentence']]\n",
    "one_time_conversation = pd.read_excel('datas/단발대화데이터셋_훈련용.xlsx',names=['emotion','sentence'])\n",
    "otc = one_time_conversation[['emotion','sentence']]\n",
    "few_times_conversation = pd.read_excel('datas/연속대화데이터셋_훈련용.xlsx',names=['emotion','sentence'])\n",
    "ftc = few_times_conversation[['emotion','sentence']]\n",
    "\n",
    "ftc = ftc[ftc['emotion']!='공포']\n",
    "ftc = ftc[ftc['emotion']!='혐오']\n",
    "otc = otc[otc['emotion']!='공포']\n",
    "otc = otc[otc['emotion']!='혐오']\n",
    "\n",
    "total_data = pd.concat([mmc,otc,ftc])\n",
    "\n",
    "#결측치제거\n",
    "total_data = total_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(total_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "total_data.loc[(total_data['emotion']=='행복'),'emotion'] = 0\n",
    "total_data.loc[(total_data['emotion']=='기쁨'),'emotion'] = 0\n",
    "total_data.loc[(total_data['emotion']=='분노'),'emotion'] = 1\n",
    "total_data.loc[(total_data['emotion']=='놀람'),'emotion'] = 2\n",
    "total_data.loc[(total_data['emotion']=='당황'),'emotion'] = 2\n",
    "total_data.loc[(total_data['emotion']=='중립'),'emotion'] = 3\n",
    "total_data.loc[(total_data['emotion']=='슬픔'),'emotion'] = 4\n",
    "total_data.loc[(total_data['emotion']=='상처'),'emotion'] = 5\n",
    "total_data.loc[(total_data['emotion']=='불안'),'emotion'] = 5\n",
    "total_data = total_data.reset_index(drop=True)\n",
    "print(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkonlpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mecab\n\u001b[1;32m      2\u001b[0m mecab \u001b[38;5;241m=\u001b[39m Mecab(dicpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/opt/anaconda3/envs/py39/lib/python3.9/site-packages/mecab-ko-dic-2.1.1-20180720\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m total_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtotal_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(mecab\u001b[38;5;241m.\u001b[39mmorphs(x)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath=\"/opt/anaconda3/envs/py39/lib/python3.9/site-packages/mecab-ko-dic-2.1.1-20180720\")\n",
    "total_data['sentence'] = total_data['sentence'].map(lambda x: ' '.join(mecab.morphs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(total_data,test_size = 0.2,random_state=123)\n",
    "train_texts = train_df['sentence'].astype(str).tolist()\n",
    "train_labels = train_df['emotion'].tolist()\n",
    "test_texts = test_df['sentence'].astype(str).tolist()\n",
    "test_labels = test_df['emotion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'monologg/kobert'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encoding = tokenizer(train_texts,truncation = True, padding = True)\n",
    "test_encoding = tokenizer(test_texts,truncation = True, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class myDataset(Dataset) : \n",
    "    def __init__(self, encodings,labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = myDataset(train_encoding, train_labels)\n",
    "test_dataset = myDataset(test_encoding, test_labels)\n",
    "batch_size = 16  # 배치 사이즈는 직접 지정해야 합니다.\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('monologg/kobert',num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#epoch, lr => hyperparameter(직접 지정해야함)\n",
    "num_epoches = 10\n",
    "learning_rate = 2e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr =learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    model.train() # 훈련 모드 지정\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epoches} - Average Loss: {average_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
